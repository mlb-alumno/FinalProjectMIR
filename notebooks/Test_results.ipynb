{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import keras as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jams\n",
    "import builtins\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "builtins.tf = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../code\"))\n",
    "\n",
    "# Add to Python path if not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import round_observation_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working = \"ADDRESS_TO_YOUR_WORKING_DIRECTORY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_spec_path, weights_path):\n",
    "    # Load the serialized model spec\n",
    "    with open(model_spec_path, \"rb\") as fd:\n",
    "        model_spec = pickle.load(fd)\n",
    "    # Reconstruct the model from the serialized spec\n",
    "    model = K.utils.deserialize_keras_object(model_spec, safe_mode=False)\n",
    "    # Load the weights from the saved file\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(working, \"model_deep\")\n",
    "split = 0\n",
    "epochs = 100\n",
    "\n",
    "model_spec_path = os.path.join(\n",
    "    output_path, \"fold{:02d}_model_{:03d}_epochs.pkl\".format(split, epochs)\n",
    ")\n",
    "weights_path = os.path.join(\n",
    "    output_path, \"fold{:02d}_weights_{:03d}_epochs.keras\".format(split, epochs)\n",
    ")\n",
    "\n",
    "model = load_model(model_spec_path, weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(working + \"/pump.pkl\"),\n",
    "    \"rb\",\n",
    ") as fd:\n",
    "    pump = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(pump, model, idx, working, refs):\n",
    "    results = {}\n",
    "    for item in tqdm(idx, desc=\"Evaluating the model\"):\n",
    "        jam = jams.load(os.path.join(refs, f\"{item}.jams\"), validate=False)\n",
    "        datum = np.load(os.path.join(working, \"pump\", f\"{item}.npz\"))[\n",
    "            \"cqt/mag\"\n",
    "        ]\n",
    "\n",
    "        output = model.predict(datum)[0]\n",
    "\n",
    "        ann = pump[\"chord_tag\"].inverse(output)\n",
    "        ann = round_observation_times(ann)\n",
    "\n",
    "        ref_ann = round_observation_times(\n",
    "            jam.annotations[\"chord\", 0], precision=10\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            results[item] = jams.eval.chord(ref_ann, ann)\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {item}: {e}\")\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient=\"index\")[\n",
    "        [\"root\", \"thirds\", \"triads\", \"tetrads\", \"mirex\", \"majmin\", \"sevenths\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = \"ADDRESS_TO_YOUR_CSV_TEST_DATASET\"\n",
    "idx = pd.read_csv(\n",
    "    test_dataset_path,\n",
    "    header=None,\n",
    "    names=[\"id\"],\n",
    ")\n",
    "pump_path = \"ADDRESS_TO_YOUR_PUMP_DIRECTORY\"\n",
    "refs = \"ADDRESS_TO_YOUR_ANNOTATIONS_REFERENCE_DIRECTORY\"\n",
    "scores = score_model(pump, model, idx[\"id\"], pump_path, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_file_path = \"ADDRESS_TO_YOUR_TEST_AUDIO_FILE\"\n",
    "input = pump.transform(test_audio_file_path)[\"cqt/mag\"]\n",
    "\n",
    "predictions = model.predict(input)[0]\n",
    "\n",
    "ann = pump[\"chord_tag\"].inverse(predictions)\n",
    "print(ann)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
